
% !Mode:: "TeX:UTF-8" 

\chapter{\hei \textbf{引言}}

%=========================================================================================
机器学习是一门利用数据中的规律来预测未知或难以观察的数据的学科，它的一个重要理论基础是统计学。统计学习理论\cite{张学工2000关于统计学习理论与支持向量机}针对有限样本情况下的机器学习问题，提出了一种新的通用学习方法，叫做支持向量机(support vector machines,SVM)。它采用结构风险最小化原则，而不是传统统计学的经验风险最小化原则\cite{cortes1995support,祁亨年2004支持向量机及其应用研究综述}，在解决小样本、 非线性和高维模式识别问题中表现出许多特有的优势，并在很大程度上克服了“维数灾难”和“过学习”等问题，在当时表现出许多优于已有方法的性能，迅速引起各领域的注意和研究兴趣，取得了大量的应用研究成果，推动了各领域的发展。

SVM是在分类与回归分析中分析数据的监督式学习模型与相关的学习算法。SVM是由 AT\&T 贝尔实验室的 Vladimir Vapnik 和他的同事[Cortes and Vapnik,1995\cite{cortes1995support}]开发的，是基于统计学习框架或 Vapnik(1982，1995)和 Chervonenkis(1974)提出的 VC 理论\cite{blumer1989learnability}的最稳健的预测方法之一。

SVM的目标是寻找一个最大化几何间隔的线性超平面，将不同类别的样本分开。SVM利用核函数将原始特征空间映射到更高维的特征空间，在此特征空间中构造线性决策面。决策面的特殊性质保证了学习机的高泛化能力从而实现非线性分类\cite{cortes1995support}。SVM的优化问题可以通过拉格朗日乘子法和二次规划求解，也可以采用一些高效的算法，如序列最小优化(SMO)算法。SVM在计算机视觉、自然语言处理、生物信息学等领域\cite{顾亚祥2011支持向量机研究进展}有广泛的应用\cite{张松兰2016支持向量机的算法及应用综述}。本文首先对SVM的理论进行系统的介绍，通过实验例子展现SVM算法的效果，同时阐述SVM在各个领域的应用情况，并对未来的研究方向进行展望。




